{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertConfig, BertModel, BertTokenizerFast, BertPreTrainedModel, TrainingArguments, Trainer\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'atis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed:int = 1004):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_intent_labels, classifier_dropout):\n",
    "        super(IntentClassifier, self).__init__()\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.linear = nn.Linear(hidden_size, num_intent_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class SlotClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_slot_labels, classifier_dropout):\n",
    "        super(SlotClassifier, self).__init__()\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.linear = nn.Linear(hidden_size, num_slot_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(x)\n",
    "    \n",
    "    \n",
    "class JointBERT(BertPreTrainedModel):\n",
    "    def __init__(self, config, intent_labels, slot_labels):\n",
    "        super().__init__(config)\n",
    "        self.num_intent_labels = len(intent_labels)\n",
    "        self.num_slot_labels = len(slot_labels)\n",
    "        self.config = config\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "        classifier_dropout = config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        \n",
    "        self.intent_classifier = IntentClassifier(config.hidden_size, self.num_intent_labels, classifier_dropout)\n",
    "        self.slot_classifier = SlotClassifier(config.hidden_size, self.num_slot_labels, classifier_dropout)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids = None,\n",
    "        attention_mask = None,\n",
    "        token_type_ids = None,\n",
    "        position_ids = None,\n",
    "        head_mask = None,\n",
    "        inputs_embeds = None,\n",
    "        intent_label_ids = None,\n",
    "        slot_label_ids = None,\n",
    "        output_attentions = None,\n",
    "        output_hidden_states = None,\n",
    "        # return_dict = None\n",
    "        ):\n",
    "        # return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            # return_dict=return_dict,\n",
    "        )   # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = outputs[1]  # [CLS]\n",
    "\n",
    "        intent_logits = self.intent_classifier(pooled_output)\n",
    "        slot_logits = self.slot_classifier(sequence_output)\n",
    "\n",
    "        total_loss = 0\n",
    "        # 1. Intent Softmax\n",
    "        if intent_label_ids is not None:\n",
    "            if self.num_intent_labels == 1:\n",
    "                intent_loss_fct = nn.MSELoss()\n",
    "                intent_loss = intent_loss_fct(intent_logits.squeeze(), intent_label_ids.squeeze())\n",
    "            else:\n",
    "                intent_loss_fct = nn.CrossEntropyLoss()\n",
    "                intent_loss = intent_loss_fct(intent_logits.view(-1, self.num_intent_labels), intent_label_ids.view(-1))\n",
    "            total_loss += intent_loss\n",
    "\n",
    "        # 2. Slot Softmax\n",
    "        if slot_label_ids is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            slot_loss = loss_fct(slot_logits.view(-1, self.num_slot_labels), slot_label_ids.view(-1))\n",
    "            total_loss += slot_loss\n",
    "\n",
    "        outputs = ((intent_logits, slot_logits),) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        outputs = (total_loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions) # Logits is a tuple of intent and slot logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset(cls, file_name, slot = False):\n",
    "        data = []\n",
    "        with open(file_name, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if slot:\n",
    "                    line = line.split()\n",
    "                data.append(line)\n",
    "        \n",
    "        return cls(data)\n",
    "            \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_train = LoadDataset.load_dataset(f'./data/{TASK}/train/seq.in')\n",
    "seq_dev = LoadDataset.load_dataset(f'./data/{TASK}/dev/seq.in')\n",
    "seq_test = LoadDataset.load_dataset(f'./data/{TASK}/test/seq.in')\n",
    "\n",
    "intent_train = LoadDataset.load_dataset(f'./data/{TASK}/train/label')\n",
    "intent_dev = LoadDataset.load_dataset(f'./data/{TASK}/dev/label')\n",
    "intent_test = LoadDataset.load_dataset(f'./data/{TASK}/test/label')\n",
    "intent_labels = LoadDataset.load_dataset(f'./data/{TASK}/intent_label_vocab')\n",
    "\n",
    "slot_train = LoadDataset.load_dataset(f'./data/{TASK}/train/seq.out', slot = True)\n",
    "slot_dev = LoadDataset.load_dataset(f'./data/{TASK}/dev/seq.out', slot = True)\n",
    "slot_test = LoadDataset.load_dataset(f'./data/{TASK}/test/seq.out', slot = True)\n",
    "slot_labels = LoadDataset.load_dataset(f'./data/{TASK}/slot_label_vocab')\n",
    "\n",
    "intent_word2idx = defaultdict(int, {k: v for v, k in enumerate(intent_labels)})\n",
    "intent_idx2word = {v: k for v, k in enumerate(intent_labels)}\n",
    "\n",
    "slot_word2idx = defaultdict(int, {k: v for v, k in enumerate(slot_labels)})\n",
    "slot_idx2word = {v: k for v, k in enumerate(slot_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = BertConfig.from_pretrained(\"bert-base-uncased\", num_labels = len(intent_idx2word), problem_type = \"single_label_classification\", id2label = intent_idx2word, label2id = intent_word2idx)\n",
    "# model_config.classifier_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing JointBERT: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing JointBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing JointBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of JointBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['intent_classifier.linear.bias', 'slot_classifier.linear.bias', 'intent_classifier.linear.weight', 'slot_classifier.linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = JointBERT.from_pretrained(\"bert-base-uncased\", config = model_config, intent_labels = intent_labels, slot_labels = slot_labels)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizeDataset:\n",
    "    def __init__(self, seqs, intent_labels, slot_labels, intent_word2idx, slot_word2idx, tokenizer):\n",
    "        self.seqs = seqs\n",
    "        self.intent_labels = intent_labels\n",
    "        self.slot_labels = slot_labels\n",
    "        \n",
    "        self.intent_word2idx = intent_word2idx\n",
    "        self.slot_word2idx = slot_word2idx\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def align_label(self, seq, intent_label, slot_label):\n",
    "        tokens = self.tokenizer(seq, padding='max_length', max_length=50, truncation=True)\n",
    "        token_idxs = tokens.word_ids()\n",
    "        \n",
    "        pre_word_idx = None\n",
    "        slot_label_ids = []\n",
    "        for word_idx in token_idxs:\n",
    "            if word_idx != pre_word_idx:\n",
    "                try:\n",
    "                    slot_label_ids.append(slot_word2idx[slot_label[word_idx]])\n",
    "                except:\n",
    "                    slot_label_ids.append(-100)\n",
    "\n",
    "            elif word_idx == pre_word_idx or word_idx is None:\n",
    "                slot_label_ids.append(-100)\n",
    "\n",
    "            pre_word_idx = word_idx\n",
    "        \n",
    "        tokens['intent_label_ids'] = [intent_word2idx[intent_label]]\n",
    "        tokens['slot_label_ids'] = slot_label_ids\n",
    "        \n",
    "        return tokens\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        bert_input = self.align_label(self.seqs[index], self.intent_labels[index], self.slot_labels[index])\n",
    "        return bert_input\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 2215, 2000, 4875, 2013, 6222, 2000, 5759, 2461, 4440, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'intent_label_ids': [13], 'slot_label_ids': [-100, 2, 2, 2, 2, 2, 73, 2, 115, 99, 100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TokenizeDataset(seq_train, intent_train, slot_train, intent_word2idx, slot_word2idx, tokenizer)\n",
    "dev_dataset = TokenizeDataset(seq_dev, intent_dev, slot_dev, intent_word2idx, slot_word2idx, tokenizer)\n",
    "test_dataset = TokenizeDataset(seq_test, intent_test, slot_test, intent_word2idx, slot_word2idx, tokenizer)\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "arguments = TrainingArguments(\n",
    "    output_dir='checkpoints',\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "\n",
    "    num_train_epochs=30,\n",
    "    learning_rate = 5e-5,\n",
    "\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    report_to = 'none',\n",
    "\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    dataloader_num_workers=0,\n",
    "    fp16=True,\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4478\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1050\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1050 03:48, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.694382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.851170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.534896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.420869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.309167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.290570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.270969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.258914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.266580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.267345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.268218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.269249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.270710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.272677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.276027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.277243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.271478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.276759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.275001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.272594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.277901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.276848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-35\n",
      "Configuration saved in checkpoints/checkpoint-35/config.json\n",
      "Model weights saved in checkpoints/checkpoint-35/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-515] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-70\n",
      "Configuration saved in checkpoints/checkpoint-70/config.json\n",
      "Model weights saved in checkpoints/checkpoint-70/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-3090] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-105\n",
      "Configuration saved in checkpoints/checkpoint-105/config.json\n",
      "Model weights saved in checkpoints/checkpoint-105/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-35] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-140\n",
      "Configuration saved in checkpoints/checkpoint-140/config.json\n",
      "Model weights saved in checkpoints/checkpoint-140/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-70] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-175\n",
      "Configuration saved in checkpoints/checkpoint-175/config.json\n",
      "Model weights saved in checkpoints/checkpoint-175/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-105] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-210\n",
      "Configuration saved in checkpoints/checkpoint-210/config.json\n",
      "Model weights saved in checkpoints/checkpoint-210/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-140] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-245\n",
      "Configuration saved in checkpoints/checkpoint-245/config.json\n",
      "Model weights saved in checkpoints/checkpoint-245/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-175] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-280\n",
      "Configuration saved in checkpoints/checkpoint-280/config.json\n",
      "Model weights saved in checkpoints/checkpoint-280/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-210] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-315\n",
      "Configuration saved in checkpoints/checkpoint-315/config.json\n",
      "Model weights saved in checkpoints/checkpoint-315/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-245] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-350\n",
      "Configuration saved in checkpoints/checkpoint-350/config.json\n",
      "Model weights saved in checkpoints/checkpoint-350/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-280] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-385\n",
      "Configuration saved in checkpoints/checkpoint-385/config.json\n",
      "Model weights saved in checkpoints/checkpoint-385/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-350] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-420\n",
      "Configuration saved in checkpoints/checkpoint-420/config.json\n",
      "Model weights saved in checkpoints/checkpoint-420/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-385] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-455\n",
      "Configuration saved in checkpoints/checkpoint-455/config.json\n",
      "Model weights saved in checkpoints/checkpoint-455/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-420] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-490\n",
      "Configuration saved in checkpoints/checkpoint-490/config.json\n",
      "Model weights saved in checkpoints/checkpoint-490/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-455] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-525\n",
      "Configuration saved in checkpoints/checkpoint-525/config.json\n",
      "Model weights saved in checkpoints/checkpoint-525/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-490] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-560\n",
      "Configuration saved in checkpoints/checkpoint-560/config.json\n",
      "Model weights saved in checkpoints/checkpoint-560/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-315] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-595\n",
      "Configuration saved in checkpoints/checkpoint-595/config.json\n",
      "Model weights saved in checkpoints/checkpoint-595/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-525] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-630\n",
      "Configuration saved in checkpoints/checkpoint-630/config.json\n",
      "Model weights saved in checkpoints/checkpoint-630/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-595] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-665\n",
      "Configuration saved in checkpoints/checkpoint-665/config.json\n",
      "Model weights saved in checkpoints/checkpoint-665/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-630] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-700\n",
      "Configuration saved in checkpoints/checkpoint-700/config.json\n",
      "Model weights saved in checkpoints/checkpoint-700/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-665] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-735\n",
      "Configuration saved in checkpoints/checkpoint-735/config.json\n",
      "Model weights saved in checkpoints/checkpoint-735/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-770\n",
      "Configuration saved in checkpoints/checkpoint-770/config.json\n",
      "Model weights saved in checkpoints/checkpoint-770/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-735] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-805\n",
      "Configuration saved in checkpoints/checkpoint-805/config.json\n",
      "Model weights saved in checkpoints/checkpoint-805/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-770] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-840\n",
      "Configuration saved in checkpoints/checkpoint-840/config.json\n",
      "Model weights saved in checkpoints/checkpoint-840/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-805] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-875\n",
      "Configuration saved in checkpoints/checkpoint-875/config.json\n",
      "Model weights saved in checkpoints/checkpoint-875/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-840] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-910\n",
      "Configuration saved in checkpoints/checkpoint-910/config.json\n",
      "Model weights saved in checkpoints/checkpoint-910/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-875] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-945\n",
      "Configuration saved in checkpoints/checkpoint-945/config.json\n",
      "Model weights saved in checkpoints/checkpoint-945/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-980\n",
      "Configuration saved in checkpoints/checkpoint-980/config.json\n",
      "Model weights saved in checkpoints/checkpoint-980/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-945] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-1015\n",
      "Configuration saved in checkpoints/checkpoint-1015/config.json\n",
      "Model weights saved in checkpoints/checkpoint-1015/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-980] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to checkpoints/checkpoint-1050\n",
      "Configuration saved in checkpoints/checkpoint-1050/config.json\n",
      "Model weights saved in checkpoints/checkpoint-1050/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-1015] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints/checkpoint-560 (score: 0.25891417264938354).\n",
      "Configuration saved in checkpoints/first_checkpoint/config.json\n",
      "Model weights saved in checkpoints/first_checkpoint/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "model.save_pretrained(f\"checkpoints/first_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_label_ids = []\n",
    "slot_label_ids = []\n",
    "\n",
    "with open(f'./data/{TASK}/test/label', 'r', encoding='utf-8') as intent_f, \\\n",
    "    open(f'./data/{TASK}/test/seq.out', 'r', encoding='utf-8') as slot_f:\n",
    "    for line in intent_f:\n",
    "        line = line.strip()\n",
    "        intent_label_ids.append(line)\n",
    "    for line in slot_f:\n",
    "        line = line.strip().split()\n",
    "        slot_label_ids.append(np.array(line))\n",
    "\n",
    "intent_label_ids = np.array(intent_label_ids)\n",
    "# slot_label_ids = np.array(slot_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, seqs):\n",
    "    model.to('cpu')\n",
    "    pred_intent_ids = []\n",
    "    pred_slot_ids = []\n",
    "\n",
    "    for i in range(len(seqs)):\n",
    "        input_seq = tokenizer(seq_test[i], return_tensors='pt')\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, (intent_logits, slot_logits) = model(**input_seq)\n",
    "\n",
    "        # Intent\n",
    "        pred_intent_ids.append(intent_idx2word[intent_logits[0].argmax().item()])\n",
    "\n",
    "        # Slot\n",
    "        slot_logits_size = slot_logits[0].shape[0]\n",
    "        slot_logits_mask = np.array(test_dataset[i]['slot_label_ids'][:slot_logits_size]) != -100\n",
    "        slot_logits_clean = slot_logits[0][slot_logits_mask]\n",
    "        pred_slot_ids.append([slot_idx2word[i.item()] for i in slot_logits_clean.argmax(dim=1)])\n",
    "\n",
    "    return np.array(pred_intent_ids), np.array(pred_slot_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file ./checkpoints/checkpoint-1050/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing JointBERT.\n",
      "\n",
      "All the weights of JointBERT were initialized from the model checkpoint at ./checkpoints/checkpoint-1050.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use JointBERT for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# last_model = JointBERT.from_pretrained(\"./checkpoints/checkpoint-1050\", config = model_config, intent_labels = intent_labels, slot_labels = slot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_732/4219308948.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(pred_intent_ids), np.array(pred_slot_ids)\n"
     ]
    }
   ],
   "source": [
    "pred_intent_ids, pred_slot_ids = predict(model, seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent_acc(preds, labels):\n",
    "    acc = (preds == labels).mean()\n",
    "    return {\n",
    "        \"intent_acc\": acc\n",
    "    }\n",
    "\n",
    "def get_slot_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return {\n",
    "        \"slot_precision\": precision_score(labels, preds),\n",
    "        \"slot_recall\": recall_score(labels, preds),\n",
    "        \"slot_f1\": f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "def get_sentence_frame_acc(intent_preds, intent_labels, slot_preds, slot_labels):\n",
    "    \"\"\"For the cases that intent and all the slots are correct (in one sentence)\"\"\"\n",
    "    # Get the intent comparison result\n",
    "    intent_result = (intent_preds == intent_labels)\n",
    "\n",
    "    # Get the slot comparision result\n",
    "    slot_result = []\n",
    "    for preds, labels in zip(slot_preds, slot_labels):\n",
    "        assert len(preds) == len(labels)\n",
    "        one_sent_result = True\n",
    "        for p, l in zip(preds, labels):\n",
    "            if p != l:\n",
    "                one_sent_result = False\n",
    "                break\n",
    "        slot_result.append(one_sent_result)\n",
    "    slot_result = np.array(slot_result)\n",
    "\n",
    "    sementic_acc = np.multiply(intent_result, slot_result).mean()\n",
    "    return {\n",
    "        \"sementic_frame_acc\": sementic_acc\n",
    "    }\n",
    "\n",
    "def compute_metrics(intent_preds, intent_labels, slot_preds, slot_labels):\n",
    "    assert len(intent_preds) == len(intent_labels) == len(slot_preds) == len(slot_labels)\n",
    "    \n",
    "    results = {}\n",
    "    intent_result = get_intent_acc(intent_preds, intent_labels)\n",
    "    print(intent_result)\n",
    "    slot_result = get_slot_metrics(slot_preds, slot_labels)\n",
    "    print(slot_result)\n",
    "    sementic_result = get_sentence_frame_acc(intent_preds, intent_labels, slot_preds, slot_labels)\n",
    "    print(sementic_result)\n",
    "\n",
    "    results.update(intent_result)\n",
    "    results.update(slot_result)\n",
    "    results.update(sementic_result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent_acc': 0.007838745800671893}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Found input variables without list of list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_intent_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintent_label_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_slot_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_label_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(intent_preds, intent_labels, slot_preds, slot_labels)\u001b[0m\n\u001b[1;32m     41\u001b[0m intent_result \u001b[38;5;241m=\u001b[39m get_intent_acc(intent_preds, intent_labels)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(intent_result)\n\u001b[0;32m---> 43\u001b[0m slot_result \u001b[38;5;241m=\u001b[39m \u001b[43mget_slot_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslot_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslot_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(slot_result)\n\u001b[1;32m     45\u001b[0m sementic_result \u001b[38;5;241m=\u001b[39m get_sentence_frame_acc(intent_preds, intent_labels, slot_preds, slot_labels)\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mget_slot_metrics\u001b[0;34m(preds, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_slot_metrics\u001b[39m(preds, labels):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(preds) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslot_precision\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslot_recall\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall_score(labels, preds),\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslot_f1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1_score(labels, preds)\n\u001b[1;32m     13\u001b[0m     }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:482\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, average, suffix, mode, sample_weight, zero_division, scheme)\u001b[0m\n\u001b[1;32m    474\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support_v1(y_true, y_pred,\n\u001b[1;32m    475\u001b[0m                                                     average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[1;32m    476\u001b[0m                                                     warn_for\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m                                                     scheme\u001b[38;5;241m=\u001b[39mscheme,\n\u001b[1;32m    480\u001b[0m                                                     suffix\u001b[38;5;241m=\u001b[39msuffix)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:130\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, suffix)\u001b[0m\n\u001b[1;32m    126\u001b[0m         true_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(true_sum, \u001b[38;5;28mlen\u001b[39m(entities_true_type))\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred_sum, tp_sum, true_sum\n\u001b[0;32m--> 130\u001b[0m precision, recall, f_score, true_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_precision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_tp_actual_correct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_tp_actual_correct\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m precision, recall, f_score, true_sum\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/seqeval/metrics/v1.py:122\u001b[0m, in \u001b[0;36m_precision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, scheme, suffix, extract_tp_actual_correct)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(average_options))\n\u001b[0;32m--> 122\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m pred_sum, tp_sum, true_sum \u001b[38;5;241m=\u001b[39m extract_tp_actual_correct(y_true, y_pred, suffix, scheme)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/seqeval/metrics/v1.py:97\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     95\u001b[0m is_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtype\u001b[39m, y_true)) \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtype\u001b[39m, y_pred))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list \u001b[38;5;241m==\u001b[39m {\u001b[38;5;28mlist\u001b[39m}:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound input variables without list of list.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_true) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_pred) \u001b[38;5;129;01mor\u001b[39;00m len_true \u001b[38;5;241m!=\u001b[39m len_pred:\n\u001b[1;32m    100\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(len_true, len_pred)\n",
      "\u001b[0;31mTypeError\u001b[0m: Found input variables without list of list."
     ]
    }
   ],
   "source": [
    "res = compute_metrics(pred_intent_ids, intent_label_ids, pred_slot_ids, slot_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
